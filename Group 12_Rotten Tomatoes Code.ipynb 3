{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea58f8e0",
   "metadata": {},
   "source": [
    "## GROUP 12\n",
    "\n",
    "## SMWA Term Project - Rotten Tomato Movies Review Analysis\n",
    "\n",
    "#### MBAA23119 Manvi Goel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72945a44",
   "metadata": {},
   "source": [
    "### (1) Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe33022",
   "metadata": {},
   "source": [
    "#### <font color='Green'>1. Loading Libraries</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab03b057",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud, STOPWORDS\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, adjusted_rand_score\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624029a",
   "metadata": {},
   "source": [
    "#### <font color='Green'>2. Importing Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"rotten_tomatoes_critic_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488fbbd",
   "metadata": {},
   "source": [
    "#### <font color='Green'>3. Exploratory Data Analysis and Data Pre-processing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c4fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Five top records of data\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e779241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "data_df.drop(['rotten_tomatoes_link','top_critic','publisher_name','review_type','review_date'], axis=1,inplace = True)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073cb832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Length of the dataset\n",
    "print('length of data is', len(data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: Shape of data\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d922e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: Size of data\n",
    "data_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5: Data information\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac717b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6: Handling null values\n",
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5124e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Rows which has null values\n",
    "\n",
    "data_df.dropna(how='any',inplace=True)\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775c757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7: Check unique target values\n",
    "data_df['review_score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68819562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The review_score is not consistent in it's scoring. So for consistency turn the review score into percentage and then scale it in the range of 1-5\n",
    "def convert_to_percentage(score):\n",
    "    numerator, denominator = map(float, score.split('/'))\n",
    "    return (numerator/denominator)*100\n",
    "\n",
    "data_df['review_score'] = data_df['review_score'].apply(convert_to_percentage)\n",
    "data_df['review_score'] = round(data_df['review_score']/20) #to keep rating between 1-5\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8534746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Check type of Review score\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bb72ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9: Data Visualization of Review Score \n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "sns.countplot(data=data_df,\n",
    "              x='review_score',\n",
    "              palette=\"mako\",\n",
    "              order = data_df['review_score'].value_counts().index)\n",
    "\n",
    "plt.title('Review Score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3111c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10: Review Length Distribution for Different Ratings\n",
    "\n",
    "# Length of word in sentence\n",
    "data_df['Length'] = data_df['review_content'].apply(lambda r: len(r.split(\" \")))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fcaa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "g = sns.FacetGrid(data_df, col='review_score',col_wrap=3, height=4, aspect=1.5)\n",
    "g.map(sns.histplot, 'Length', kde=True)\n",
    "g.set_axis_labels('Length', 'Count')\n",
    "g.set_titles('Rating {col_name}')\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Review Length Distribution for Different Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a4cfe",
   "metadata": {},
   "source": [
    "### (2) Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501b7ce",
   "metadata": {},
   "source": [
    "#### <font color='Green'>1. Sentiment Analysis using VADER </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9836a7c0",
   "metadata": {},
   "source": [
    "We will perform sentiment analysis to analyze sentiment of each review and classify it as positive, negative, or neutral. And results will be compared with the real rating of the restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab851bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Sentiment Analyzer - VADER \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2136e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94645ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined a function to classify the sentiment of a review\n",
    "\n",
    "# Initialize the sentiment intensity analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Analyze sentiments using VADER\n",
    "def get_sentiment(review):\n",
    "    scores = sia.polarity_scores(review)\n",
    "    sentiment_score = scores['compound']\n",
    "    if sentiment_score > 0.1:\n",
    "        return 'positive'\n",
    "    elif sentiment_score < -0.1:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "    \n",
    "# Apply function on dataset copy\n",
    "data_df = data_df.copy()\n",
    "data_df['Predicted_Sentiment'] = data_df['review_content'].apply(get_sentiment)\n",
    "\n",
    "# Print the number of positive, negative, and neutral reviews\n",
    "print(\"Number of positive reviews:\", len(data_df[data_df['Predicted_Sentiment'] == 'positive']))\n",
    "print(\"Number of negative reviews:\", len(data_df[data_df['Predicted_Sentiment'] == 'negative']))\n",
    "print(\"Number of neutral reviews:\", len(data_df[data_df['Predicted_Sentiment'] == 'neutral']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccad3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the rating column to create new column true sentiment\n",
    "data_df['Actual_Sentiment'] = data_df['review_score'].map({0: 'negative',\n",
    "                                           1: 'negative', \n",
    "                                           2: 'negative', \n",
    "                                           3: 'neutral', \n",
    "                                           4: 'positive', \n",
    "                                           5: 'positive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16030816",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd26fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting confusion matrix\n",
    "cm = confusion_matrix(data_df['Actual_Sentiment'], data_df['Predicted_Sentiment'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "# Create heatmap\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted sentiment')\n",
    "plt.ylabel('Actual sentiment')\n",
    "plt.title('Confusion matrix for sentiment analysis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfbd21b",
   "metadata": {},
   "source": [
    "#### <font color='Green'>2. Sentiment Analysis using NRClex (NRC Emotion Lexicon)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404d1d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install NRCLex\n",
    "from nrclex import NRCLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e22665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiments and emotions using NRClex\n",
    "sentiments = []\n",
    "\n",
    "for review in data_df['review_content']:\n",
    "    emotion_analyzer = NRCLex(review)\n",
    "    emotions = emotion_analyzer.affect_frequencies\n",
    "    sentiments.append(emotions)\n",
    "\n",
    "# Create a new DataFrame with sentiment information\n",
    "sentiments_df = pd.DataFrame(sentiments)\n",
    "\n",
    "# Combine with the original DataFrame\n",
    "result_df = pd.concat([data_df, sentiments_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc404f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bfde17",
   "metadata": {},
   "source": [
    "### (3) Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ffbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "\n",
    "data_df.drop(data_df.columns[3], axis='columns',  inplace = True) #Length\n",
    "data_df.drop(data_df.columns[-1], axis='columns',  inplace = True) #Actual Sentiment\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c308996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_string(sentences): \n",
    "    sentence = ''\n",
    "    for words in sentences:\n",
    "        sentence += words\n",
    "    sentence = re.sub('[^A-Za-z0-9 ]+', '', sentence)\n",
    "    sentence = re.sub(r'http\\S+', '', sentence)\n",
    "    sentence = re.sub(r'nt', '', sentence)\n",
    "    sentence = sentence.lower()\n",
    "    return sentence \n",
    "\n",
    "def get_word(sentence):\n",
    "    return nltk.RegexpTokenizer(r'\\w+').tokenize(sentence)\n",
    "\n",
    "def remove_stopword(word_tokens):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    for word in word_tokens:\n",
    "        if word not in stopword_list: \n",
    "            filtered_tokens.append(word) \n",
    "    return filtered_tokens \n",
    "\n",
    "def lemmatize_words(filtered_tokens):\n",
    "    lemm = WordNetLemmatizer() \n",
    "    cleaned_tokens = [lemm.lemmatize(word) for word in filtered_tokens]\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_freq_df(cleaned_tokens): \n",
    "    fdist = nltk.FreqDist(cleaned_tokens)\n",
    "    freq_df = pd.DataFrame.from_dict(fdist, orient='index')\n",
    "    freq_df.columns = ['Frequency']\n",
    "    freq_df.index.name = 'Term'\n",
    "    freq_df = freq_df.sort_values(by=['Frequency'], ascending=False)\n",
    "    freq_df = freq_df.reset_index()\n",
    "    return freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2523ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(series):\n",
    "    all_string = get_all_string(series)\n",
    "    words = get_word(all_string)\n",
    "    filtered_tokens = remove_stopword(words)\n",
    "    cleaned_tokens = lemmatize_words(filtered_tokens)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bcaa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_text_distribution(x_df, y_df, color, title, xaxis_text, yaxis_text):\n",
    "    \n",
    "    fig = px.bar(x=x_df, \n",
    "                y=y_df,\n",
    "                color=y_df,\n",
    "                text=y_df,\n",
    "                color_continuous_scale=color)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=title,\n",
    "        template='plotly_white',\n",
    "        xaxis=dict(\n",
    "            title=xaxis_text,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=yaxis_text,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker_line_color='black', \n",
    "                    marker_line_width=1.5, \n",
    "                    opacity=0.8)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0610a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordcloud(freq_df, title, color):\n",
    "    \n",
    "    data = freq_df.set_index('Term').to_dict()['Frequency']\n",
    "    \n",
    "    plt.figure(figsize = (20,15))\n",
    "    wc = WordCloud(width=800, \n",
    "               height=400, \n",
    "               max_words=100,\n",
    "               colormap= color,\n",
    "               max_font_size=200,\n",
    "               min_font_size = 1 ,\n",
    "               random_state=8888, \n",
    "               background_color='white').generate_from_frequencies(data)\n",
    "    \n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e61398",
   "metadata": {},
   "source": [
    "### <font color='Green'>Word Cloud</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1bdfcf",
   "metadata": {},
   "source": [
    "#### Positive Sentiment Text Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80d94e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = preprocess(data_df.loc[data_df['Predicted_Sentiment'] == 'positive']['review_content'])\n",
    "positive_words\n",
    "positive_words_df = create_freq_df(positive_words)\n",
    "top10_positive_words = positive_words_df[:10]\n",
    "\n",
    "plot_text_distribution(top10_positive_words['Term'], top10_positive_words['Frequency'],\n",
    "                   'Greens', 'Top 10 Positive Sentiment Text Distribution', 'Text', 'Number of Texts')\n",
    "create_wordcloud(positive_words_df, 'Positive Sentiment Text Distribution', 'BuGn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6819d339",
   "metadata": {},
   "source": [
    "#### Negative Sentiment Text Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = preprocess(data_df.loc[data_df['Predicted_Sentiment'] == 'negative']['review_content'])\n",
    "negative_words_df = create_freq_df(negative_words)\n",
    "top10_negative_words = negative_words_df[:10]\n",
    "\n",
    "plot_text_distribution(top10_negative_words['Term'], top10_negative_words['Frequency'],\n",
    "                  'Reds', 'Top 10 Negative Sentiment Text Distribution', 'Text', 'Number of Texts')\n",
    "create_wordcloud(negative_words_df, 'Negative Sentiment Text Distribution', 'OrRd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31fda1",
   "metadata": {},
   "source": [
    "#### Neutral Sentiment Text Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = preprocess(data_df.loc[data_df['Predicted_Sentiment'] == 'neutral']['review_content'])\n",
    "negative_words_df = create_freq_df(negative_words)\n",
    "top10_negative_words = negative_words_df[:10]\n",
    "\n",
    "plot_text_distribution(top10_negative_words['Term'], top10_negative_words['Frequency'],\n",
    "                  'Greys', 'Top 10 Neutral Sentiment Text Distribution', 'Text', 'Number of Texts')\n",
    "create_wordcloud(negative_words_df, 'Neutral Sentiment Text Distribution', 'binary_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b94adf7",
   "metadata": {},
   "source": [
    "#### Overall Sentiment Text Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bce79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = preprocess(data_df['review_content'])\n",
    "words\n",
    "words_df = create_freq_df(words)\n",
    "top10_words = words_df[:20]\n",
    "\n",
    "plot_text_distribution(top10_words['Term'], top10_words['Frequency'],\n",
    "                   'Blues', 'Top 20 words Sentiment Text Distribution', 'Text', 'Number of Texts')\n",
    "create_wordcloud(positive_words_df, 'words Sentiment Text Distribution', 'PuBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a054571",
   "metadata": {},
   "source": [
    "### (4) Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3299184b",
   "metadata": {},
   "source": [
    " #### <font color='Green'>Transforming the Dataset Using TF-IDF Vectorizer</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9727351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features=10000, tokenizer = word_tokenize)\n",
    "X = tfidf.fit_transform(data_df['review_content'])\n",
    "y = data_df['Predicted_Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a090b",
   "metadata": {},
   "source": [
    "#### <font color='Green'>Splitting the Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c8e06",
   "metadata": {},
   "source": [
    " #### <font color='Green'>Model Building</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacfda53",
   "metadata": {},
   "source": [
    "##### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddea8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "predicted_lr = lr.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print classification report\n",
    "accuracy_lr = accuracy_score(y_test, predicted_lr)\n",
    "print('Accuracy:', accuracy_lr)\n",
    "print('\\n')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix\n",
    "cm_lr = confusion_matrix(y_test, predicted_lr)\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize = (6,4))\n",
    "sns.set(font_scale = 1.3)\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "sns.heatmap(cm_lr, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels, cbar=False)\n",
    "plt.xlabel('Predicted sentiment')\n",
    "plt.ylabel('True sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9900784",
   "metadata": {},
   "source": [
    "##### 2. Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1936fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "svc = LinearSVC(random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "predicted_svc = svc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print classification report\n",
    "accuracy_svc = accuracy_score(y_test, predicted_svc)\n",
    "print('Accuracy:', accuracy_svc)\n",
    "print('\\n')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02835d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix\n",
    "cm_svc = confusion_matrix(y_test, predicted_svc)\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize = (6,4))\n",
    "sns.set(font_scale = 1.3)\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "sns.heatmap(cm_svc, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels, cbar=False)\n",
    "plt.xlabel('Predicted sentiment')\n",
    "plt.ylabel('True sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc715b17",
   "metadata": {},
   "source": [
    "##### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predicted_rf = rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, predicted_rf)\n",
    "print('Accuracy:', accuracy_rf)\n",
    "print('\\n')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8928363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix\n",
    "cm_rf = confusion_matrix(y_test, predicted_rf)\n",
    "\n",
    "# heatmap\n",
    "plt.figure(figsize = (6,4))\n",
    "sns.set(font_scale = 1.3)\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "sns.heatmap(cm_rf, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels, cbar=False)\n",
    "plt.xlabel('Predicted sentiment')\n",
    "plt.ylabel('True sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed9047f",
   "metadata": {},
   "source": [
    "##### 4. Naive Bayes Multinominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3505a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "predicted_nb = nb.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_nb = accuracy_score(y_test, predicted_nb)\n",
    "print('Accuracy:', accuracy_nb)\n",
    "print('\\n')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2180b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix\n",
    "cm_nb = confusion_matrix(y_test, predicted_nb)\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize = (6,4))\n",
    "sns.set(font_scale = 1.3)\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "sns.heatmap(cm_nb, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels, cbar=False)\n",
    "plt.xlabel('Predicted sentiment')\n",
    "plt.ylabel('True sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cdf4c1",
   "metadata": {},
   "source": [
    "##### Compare models performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8897cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Models = ['Logistic Regression', 'SVC', 'Random Forest', 'Naive Bayes Multinominal']\n",
    "Scores = [accuracy_lr, accuracy_svc, accuracy_rf, accuracy_nb]\n",
    "performance = pd.DataFrame(list(zip(Models, Scores)), \n",
    "                          columns = ['Models', 'Accuracy_score'])\\\n",
    "                            .sort_values('Accuracy_score', ascending=False)\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee22943",
   "metadata": {},
   "source": [
    "### (5) Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46695360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "#nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = list(stop_words)\n",
    "stop_words1 = ['placeholder_for_any_customize_words'] + stop_words\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = [word for word in text.split() if word not in stop_words1]  # Remove stopwords\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2af5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['preprocessed_reviews'] = data_df['review_content'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac16351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "vectorizer = CountVectorizer(ngram_range = (1,2), max_features=1000, max_df=0.5)\n",
    "# see the above parameters and comment -- ? \n",
    "\n",
    "X = vectorizer.fit_transform(data_df['preprocessed_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA Model - This is used for Topic Modeling popularly \n",
    "# Specify beforehand the number of topics to be identified. This is given by number of components of LDA parameter\n",
    "# set the 'K' - number of topics\n",
    "number_of_topics = 5\n",
    "lda = LatentDirichletAllocation(n_components=number_of_topics, random_state=42)\n",
    "lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783bdb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display topics and top words for each topic\n",
    "feature_names = vectorizer.get_feature_names_out() # Get all the features/tokens names in vectorized data\n",
    "\n",
    "num_words = 10            # Choose 'N' here the number of words to show for each LDA topic, to identify the topic \n",
    "\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    top_words_idx = topic.argsort()[-num_words:][::-1]\n",
    "    top_words = [feature_names[i] for i in top_words_idx]\n",
    "    print(f\"Topic {idx+1}: {', '.join(top_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b4f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Clouds for Topics\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(zip(feature_names, topic)))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(f\"Topic {idx+1} - Word Cloud\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3810378d",
   "metadata": {},
   "source": [
    "### (6) Text clustering for reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2cdfe4",
   "metadata": {},
   "source": [
    "We can use text clustering algorithms, such as K-means, to group similar reviews into clusters based on the similarity of their contents. The goal of clustering is to identify underlying patterns or structures in the data, which can be useful for recommendation systems, for example improving customer service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c76a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose only negative reviews\n",
    "#df_neg = data_df[data_df['Rating'] <= 2]\n",
    "\n",
    "# Convert text to numerical vectors using TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(data_df['review_content'])\n",
    "\n",
    "# Cluster the documents using K-Means algorithm\n",
    "optimal_clusters = 3\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, init='k-means++', max_iter=100, n_init=1, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Evaluate the performance of the clustering using adjusted Rand index\n",
    "y_true = data_df['review_score'].values\n",
    "y_pred = kmeans.labels_\n",
    "print('Adjusted Rand index:', adjusted_rand_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5677f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the dimensionality of the vectors to 2 using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7aaba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top features for each cluster\n",
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for i in range(optimal_clusters):\n",
    "    print(f\"Cluster {i+1} top terms:\", [terms[ind] for ind in order_centroids[i, :10]])\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1564399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters\n",
    "colors = ['red', 'green', 'blue']\n",
    "for i in range(optimal_clusters):\n",
    "    plt.scatter(X_pca[kmeans.labels_ == i, 0], X_pca[kmeans.labels_ == i, 1], s=50, c=colors[i], label='Cluster {}'.format(i))\n",
    "plt.legend()\n",
    "plt.title('Text Clustering using K-Means')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfa5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most frequent words in each cluster\n",
    "top_words = 40\n",
    "for i in range(optimal_clusters):\n",
    "    cluster_reviews = data_df['review_content'][kmeans.labels_ == i]\n",
    "    cluster_text = ' '.join(cluster_reviews)\n",
    "    wordcloud = WordCloud(width=600, height=400, max_words=top_words, background_color='white').generate(cluster_text)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Cluster {}: Most Frequent Words'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae416b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal number of clusters using silhouette score\n",
    "silhouette_scores = []\n",
    "for n_clusters in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(X)\n",
    "    silhouette_scores.append(silhouette_score(X, cluster_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4717fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Scree Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(2, 11), silhouette_scores, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Scree Plot\")\n",
    "plt.xticks(range(2, 21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4412c24",
   "metadata": {},
   "source": [
    "Through silhouette score we identify that optimal number of clusters are 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c49e3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e0216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
